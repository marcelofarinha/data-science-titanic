{"cells":[{"metadata":{},"cell_type":"markdown","source":" # PROJETO TITANIC","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<p align=\"center\">\n  <img width=\"550\" height=\"250\" src=\"https://canalhistoria.pt/wp-content/uploads/2016/05/1.Portada.jpg\">\n</p>\n\n### O naufrágio do RMS Titanic é uma das tragédias mais famosas da história, originando diversos livros, filmes e afins. É válido lembrar que a história narrada de forma célebre por James Cameron em seu filme de 1997, ilustra perfeitamente o motivo deste desafio. Vamos começar com uma breve perspectiva sobre o tema: O Titanic foi um navio de passageiros construído nos estaleiros da Harland and Wolff durante o período de março de 1909 a maio de 1911 em Belfast no Reino Unido. Naquela época, a construção do Titanic levou cerca de 2 anos e custou 7,5 milhões de dólares. A embarcação partiu em sua viagem inaugural de Southampton para Nova Iorque em 10 de abril de 1912, com passagem em Cherbourg-Octeville na França e em Queenstown na Irlanda. Devido a sua excelente projetação, gerou boatos de que a embarcação seria \"inafundável\", porém, às 23h40min do dia 14 de abril, a embarcação se chocou contra um iceberg. Em 15 de abril de 1912, o Titanic afundou matando 1.502 dos 2.224 passageiros e tripulantes, ou seja, apenas 32% desses passageiros sobreviveram ao naufrágio, tornando assim o maior desastre marítimo em tempos de paz da história.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. BUSINESS UNDERSTANDING\n\n## 1.1. Problemática\n>### Os motivos que contribuíram para o naufrágio foram: fatores naturais, como o clima; e causas humanas, como negligência, pois não haviam botes salva-vidas suficientes para os passageiros e tripulantes e muitos dos botes salva-vidas não estavam com a sua capacidade máxima de pessoas a bordo, e se estivessem seria possível salvar 53% dos passageiros, mas apenas 32% deles sobreviveram.\n>### Embora aqueles que escaparam com vida tiveram sua sorte, alguns grupos de pessoas eram mais propensos a escaparem da morte do que outros. A maioria do sobreviventes eram mulheres, crianças e passageiros da 1ª Classe, deixando evidente que existe algum padrão que pode ser extraído dos dados brutos, que será apresentado ao longo do projeto.\n\n>### Então, eis que surge a questão: Quais eram as características das pessoas que sobreviveram ao desastre? Haveria um padrão entre as características dos sobreviventes?  Por que certas pessoas sobreviveram e outras não?\n<p align=\"center\">\n  <img width=\"550\" height=\"250\" src=\"https://digitalks.com.br/wp-content/uploads/2018/08/blockchain-marketing-digital.png\">\n</p>\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1.2. Objetivo do Projeto\n\n>### Construir um algoritmo de *Machine Learning* para prever o índice de sobrevivência dos passageiros do *Titanic*, que tenha pelo menos 80% de acurácia, baseadas nas *features* dos *datasets* disponibilizados no desafio do *[Kaggle](https://www.kaggle.com/c/titanic)*.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1.3. Metodologia\n\n> ### Será utilizada o CRISP-DM (*Cross Industry Standard Process for Data Mining*), é uma metodologia de processo de mineração de dados, capaz de transformar os dados em conhecimento e informações para estratégias de negócio.\n> ## Classificador de dados utilizado no *Machine Learning*:\n> * Cross Validation com K-fold;\n> * KNN;\n> * Árvore de Decisão; \n> * Florestas Aleatórias (Random Forest);\n> * Naive Bayes;\n> * Support Vector Machine (SVM);\n> * QDA; \n> * Regressão Linear.\n\n> ## Tecnologias utilizadas:\n\n> ### Ambiente de desenvolvimento:\n>> * Jupyter Notebook - Servidor do Kaggle\n\n> ### Linguagem de programação:\n>> *  Python\n\n> ### Bibliotecas:\n>> *  Pandas\n>> *  Numpy\n>> *  Seaborn\n>> *  Matplotlib\n>> *  SciKit Learn\n\n> ### Formato dos *datasets*:\n>> *  .csv (valores separados por vírgulas)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. DATA UNDERSTANDING\n> * Importar as bibliotecas utilizadas;\n> * Importar os *datasets* utilizando a biblioteca Pandas;\n> * Analisar os *datasets*.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ### Arquivos disponibilizados pelo *[Kaggle](https://www.kaggle.com/c/titanic)*:\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Importação de bibliotecas e definição de váriaveis de **treino** e de **teste** com a biblioteca *pandas*, utilizando os caminhos dos arquivos mostrados no código anterior.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sb\nimport matplotlib.pyplot as pl\n\n%matplotlib inline\n\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest  = pd.read_csv('/kaggle/input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### A partir disto, vamos criar um algoritmo capaz de dizer se uma pessoa sobreviveria à tragédia do Titanic, baseado em *Features* que o próprio desafio nos disponibiliza através de um algoritmo de *Machine Learning*.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ### Analisando o *dataset*:\n\n> * **Conjunto de treinamento**\n>> #### A função abaixo, nos mostra as 5 primeiras linhas do *Train Dataset*.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * **Conjunto de teste**\n>> #### A função abaixo, nos mostra as 5 primeiras linhas do *Test Dataset*.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Abaixo mostra a dimensão do conjunto de dados de treino:\n>> - 891 registros (linhas);\n>> - 12  *features* (colunas).\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Abaixo mostra a dimensão do conjunto de dados de teste:\n>> - 418 registros (linhas);\n>> - 11  *features* (colunas).\n\n> Obs: Tem 1 coluna a menos, pois é a *feature* que indica se o passageiro sobreviveu (1) ou não (0) e não deve estar no conjunto de testes, pois é a previsão que o algoritmo nos mostrará.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Abaixo mostra as informações de cada *features* do conjunto de treino:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Abaixo mostra as informações de cada *features* do conjunto de teste:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Os *datasets* possuem uma quantidade de dados nulos (sem valor) em algumas *features*.\n> *  Abaixo apresenta a quantidade de dados nulos do conjunto de treino:\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Abaixo apresenta a quantidade de dados nulos do conjunto de teste:\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### A seguir, foram escolhidos alguns gráficos a serem plotados para a visualização de como as *features* se comportam:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def grafico(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar', stacked=True, figsize=(10,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Gráfico baseado no sexo:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grafico('Sex')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Gráfico baseado na classe de embarque:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grafico('Pclass')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Gráfico baseado no número de irmãos/cônjuges a bordo:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grafico('SibSp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Gráfico baseado no número de pais/filhos a bordo:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grafico('Parch')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Gráfico baseado em qual porto o navio embarcou:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grafico('Embarked')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. DATA PREPARATION\n\n> * Criar classes baseados nos pronomes de tratamento;\n> * Preencher os valores vazios das idades, baseados nos nas médias de idade dos pronomes de tratamento;\n> * Substituir valores da *feature* 'Sex' para valores numéricos;\n> * Criar classes para as idades.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ### Nesta etapa, utiliza-se a *feature* 'Name' para criar a *feature* 'Title', que nada mais é do que a extração do título dos nomes da pessoas,isto é, os pronomes de tratamento, por exemplo: Mr., Miss., etc.:\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test = [train, test]\nfor dataset in train_test:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> *  Contagem dos títulos presentes no conjunto de treino:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Contagem de cada titulo presente no conjunto de teste:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ###  Transformando os títulos em representação numérica:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"title_map = {\"Mr\": 0,\n            \"Miss\": 1,\n            \"Mrs\": 2,\n            \"Master\": 3,\n            \"Dr\": 3,\n            \"Rev\": 3,\n            \"Col\": 3,\n            \"Major\": 3,\n            \"Mlle\": 3,\n            \"Ms\": 3,\n            \"Don\": 3,\n            \"Lady\": 3,\n            \"Jonkheer\": 3,\n            \"Countess\": 3,\n            \"Mme\": 3,\n            \"Sir\": 3,\n            \"Capt\": 3}\nfor dataset in train_test:\n    dataset['Title'] = dataset['Title'].map(title_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"Title\"].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Abaixo mostra os valores atribuídos para a *feature* 'Title' do conjunto de treino:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grafico('Title')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Vamos retirar a *feature* 'Name' de ambos os conjuntos:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### A seguir, substituímos os valores 'male' e 'female' da *feature* 'Sex' por 0 e 1 respectivamente, para criarmos o gráfico de sobreviventes entre homens e mulheres:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sex_map = {\"male\": 0, \"female\": 1}\nfor dataset in train_test:\n    dataset['Sex'] = dataset['Sex'].map(sex_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grafico('Sex')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Como existem várias idades presentes nos conjuntos de dados, se criássemos um gráfico não teria como saber qual a idade que mais sobreviveu à tragédia, pois teríamos muitos resultados...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sb.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sb.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\npl.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Então, criamos classes e classificamos as idades por faixas etárias:\n| Faixa etária | Classe |\n|--------------|--------|\n| 0 - 16       | 0      |\n| 17 - 26      | 1      |\n| 27 - 36      | 2      |\n| 37 - 62      | 3      |\n| Maior que 62 | 4      |\n \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> * Assim criando apenas 5 classes, vamos obter o resultado apenas das 5 classes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in train_test:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] =0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 62), 'Age'] = 4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Desta forma, tornamos o gráfico mais limpo e fácil de ser interpretado:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grafico('Age')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Nesta etapa, um gráfico é plotado para analisar os lugares de embarque das pessoas:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1,Pclass2,Pclass3])\ndf.index = ['1st class', '2nd class', '3rd class']\ndf.plot(kind='bar', stacked=True, figsize=(10,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Mais do que 50% de cada classe veio do porto 'S', então está sendo preenchido os vazios com 'S'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in train_test:\n    dataset['Embarked'] =  dataset['Embarked'].fillna('S')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Nesta etapa, é feito um mapping dos lugares de embarque para números, transformando as letras em representação númerica, isto é, atribuímos aos valores da feature 'Embarked' os numeros 0, 1 e 2:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"emb_map = {\"S\": 0,\n           \"C\": 1,\n           \"Q\": 2}\nfor dataset in train_test:\n    dataset['Embarked'] = dataset['Embarked'].map(emb_map)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### A seguir, é preenchido os valores vazios das tarifas com a média de cada conjunto:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Foi criada uma faixa de valores para a tarifa:\n| Faixa valores| Classe |\n|--------------|--------|\n| 0 - 17       | 0      |\n| 18 - 30      | 1      |\n| 31 - 100     | 2      |\n| > 100        | 3      |","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in train_test:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] =0\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2\n    dataset.loc[(dataset['Fare'] > 100), 'Fare'] = 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Aqui foi feito um *substring* utilizando apenas a primeira posição da cabine, ou seja, apenas as letras:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Cabin.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in train_test:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * O gráfico abaixo mostra a quantidade de passageiros em determinadas seções de cabines baseada nas suas classes:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1,Pclass2,Pclass3])\ndf.index = ['1st class', '2nd class', '3rd class']\ndf.plot(kind='bar', stacked=True, figsize=(10,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### É feito um *mapping* das cabines substituindo elas por valores númericos que variam de 0.4 em 0.4:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cab_map = {\"A\": 0,\n           \"B\": 0.4,\n           \"C\": 0.8,\n           \"D\": 1.2,\n           \"E\": 1.6,\n           \"F\": 2.0,\n           \"G\": 2.4,\n           \"T\": 2.8}\nfor dataset in train_test:\n    dataset['Cabin'] = dataset['Cabin'].map(cab_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Aqui começa a análise relacionado ao tamanho da família dos passeiros:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"]  + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"]  + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sb.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sb.kdeplot, 'FamilySize', shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Aqui também é feito um mapping do tamanho das famílias, substituindo elas por valores númericos que variam de 0.4 em 0.4:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"family_map = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### E para finalizar a preparação de dados do *dataset*, foi definido que:\n> * As *features* 'SibSP' e 'Parch' vão ser *dropadas*, pois  não são mais necessárias;\n> * As *features* 'Ticket' e 'PassengerId' não serão importantes para nossa análise;\n> * E no conjunto de treino a *feature* 'Survived' vai ser eliminada.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)\ntrain_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. MODELING","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ### Foram definidos alguns classificadores que serão utilizados para analisarmos qual será o melhor método a ser aplicado no algoritmo, baseado no resultado da apuração *SCORE*:\n> * Cross Validation com K-fold;\n> * KNN;\n> * Árvore de Decisão; \n> * Florestas Aleatórias (Random Forest);\n> * Naive Bayes;\n> * Support Vector Machine (SVM);\n> * QDA; \n> * Regressão Linear.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ### Importando classificadores:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn import linear_model\nfrom sklearn.svm import SVC\n\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. EVALUATION\n> * Será verificado se os resultados foram atingidos baseados no objetivo definido do projeto: **atingir pelo menos 80% de acurácia.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ## Cross Validation com K-fold:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## KNN:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)\nround(np.mean(score)*100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Árvore de Decisão:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)\nround(np.mean(score)*100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Florestas Aleatórias (Random Forest):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)\nround(np.mean(score)*100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)\nround(np.mean(score)*100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">## Support Vector Machine (SVM):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)\nround(np.mean(score)*100,2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## QDA:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = QuadraticDiscriminantAnalysis()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)\nround(np.mean(score)*100,2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Regressão Linear:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = linear_model.LinearRegression()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1)\nprint(score)\nround(np.mean(score)*100,2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. DEPLOYMENT\n\n> ### Criamos um pequeno *dataset* com os dados dos integrantes do grupo do projeto para o algoritmo ser executado e testarmos o seu funcionamento.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC()\n\nclf.fit(train_data, target)\n\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\n\nprediction = clf.predict(test_data)\n\ntest_data2 = pd.read_csv('/kaggle/input/testes/teste.csv')\nprediction2 = clf.predict(test_data2)\n\nprint(prediction2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * O resultado apresentado acima, mostra que dos 5 integrantes do grupo, baseado nas *features*, apenas 1 integrante sobreviveria.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ### Por fim, executamos o algoritmo no conjunto de teste do projeto para prever se cada um dos passeiros do Titanic sobreviveria à tragédia ou não, baseado na análise, definição das técnicas e *datasets* disponibilizados pelo desafio do [Kaggle](https://www.kaggle.com/c/titanic).\n> ### O classificador escolhido para fazer a predição do conjunto de dados foi o **Support Vector Machine (SVM)**, no qual obtivemos o *score* mais alto, de 83,5.  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/working/submission.csv')\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
